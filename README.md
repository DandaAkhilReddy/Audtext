<div align="center">

# ğŸ™ï¸ Audtext

### *Transform Audio into Text & Insights â€” 100% Local, 100% Private*

[![GitHub stars](https://img.shields.io/github/stars/DandaAkhilReddy/Audtext?style=for-the-badge&logo=github&color=yellow)](https://github.com/DandaAkhilReddy/Audtext/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/DandaAkhilReddy/Audtext?style=for-the-badge&logo=github&color=blue)](https://github.com/DandaAkhilReddy/Audtext/network/members)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![React](https://img.shields.io/badge/React-18-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://react.dev)

<br/>

<img src="https://raw.githubusercontent.com/DandaAkhilReddy/Audtext/main/docs/demo.gif" alt="Audtext Demo" width="800"/>

<br/>

**[ğŸš€ Quick Start](#-quick-start)** â€¢ **[âœ¨ Features](#-features)** â€¢ **[ğŸ“– Documentation](#-installation)** â€¢ **[ğŸ¤ Contributing](#-contributing)**

</div>

---

## ğŸŒŸ Why Audtext?

<table>
<tr>
<td width="50%">

### ğŸ”’ **Privacy First**
Your audio **never leaves your computer**. Everything runs locally using OpenAI's Whisper model - no cloud uploads, no API keys needed, no subscription costs.

</td>
<td width="50%">

### âš¡ **Lightning Fast**
CPU-optimized transcription with `faster-whisper`. Process 1-hour audio files in minutes, not hours. Real-time progress tracking included.

</td>
</tr>
<tr>
<td width="50%">

### ğŸ¤– **AI-Powered Summaries**
Get intelligent summaries using Ollama's local LLM. Choose from concise, detailed, or bullet-point formats - all without API costs.

</td>
<td width="50%">

### ğŸ“¤ **Multiple Export Formats**
Export your transcripts as **TXT**, **SRT**, **VTT**, or **JSON**. Perfect for subtitles, documentation, or further processing.

</td>
</tr>
</table>

---

## âœ¨ Features

<div align="center">

| Feature | Description |
|:-------:|:------------|
| ğŸµ **Multi-Format Support** | MP3, WAV, M4A, FLAC, OGG, WEBM, MP4 |
| ğŸ“Š **Real-Time Progress** | Watch transcription progress live |
| ğŸ• **Timestamps** | Every segment includes precise timing |
| ğŸŒ **Multi-Language** | Automatic language detection |
| ğŸ“± **Responsive UI** | Beautiful interface on any device |
| ğŸ”„ **No Size Limits** | Upload audio files of any length |

</div>

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AUDTEXT                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              â”‚     â”‚              â”‚     â”‚              â”‚   â”‚
â”‚   â”‚   Frontend   â”‚â”€â”€â”€â”€â–¶â”‚   Backend    â”‚â”€â”€â”€â”€â–¶â”‚   Whisper    â”‚   â”‚
â”‚   â”‚   React 18   â”‚     â”‚   FastAPI    â”‚     â”‚   (Local)    â”‚   â”‚
â”‚   â”‚              â”‚     â”‚              â”‚     â”‚              â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                               â”‚                                  â”‚
â”‚                               â–¼                                  â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                        â”‚              â”‚                         â”‚
â”‚                        â”‚   Ollama     â”‚                         â”‚
â”‚                        â”‚   (LLM)      â”‚                         â”‚
â”‚                        â”‚              â”‚                         â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

| Requirement | Version | Installation |
|-------------|---------|--------------|
| Python | 3.11+ | [python.org](https://python.org) |
| Node.js | 18+ | [nodejs.org](https://nodejs.org) |
| FFmpeg | Latest | See below |
| Ollama | Latest | [ollama.ai](https://ollama.ai) |

<details>
<summary><b>ğŸ“¦ Install FFmpeg</b></summary>

```bash
# Windows (winget)
winget install ffmpeg

# Windows (chocolatey)
choco install ffmpeg

# macOS
brew install ffmpeg

# Linux (Ubuntu/Debian)
sudo apt install ffmpeg
```

</details>

### âš¡ 3-Step Setup

```bash
# 1ï¸âƒ£ Clone & Setup Backend
git clone https://github.com/DandaAkhilReddy/Audtext.git
cd Audtext/backend
python -m venv venv && .\venv\Scripts\activate  # Windows
pip install -r requirements.txt

# 2ï¸âƒ£ Setup Frontend
cd ../frontend
npm install

# 3ï¸âƒ£ Download AI Model
ollama pull llama3.1:8b
```

### ğŸ¬ Run the App

Open **3 terminals**:

```bash
# Terminal 1 - AI Engine
ollama serve

# Terminal 2 - Backend (activate venv first!)
cd Audtext/backend && .\venv\Scripts\activate
uvicorn main:app --reload --port 8000

# Terminal 3 - Frontend
cd Audtext/frontend
npm run dev
```

ğŸŒ **Open** â†’ [http://localhost:5173](http://localhost:5173)

---

## ğŸ“– Installation

<details>
<summary><b>ğŸ”§ Detailed Backend Setup</b></summary>

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate it
# Windows:
.\venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

**Dependencies include:**
- `fastapi` - Modern web framework
- `faster-whisper` - Optimized speech recognition
- `httpx` - Async HTTP client for Ollama
- `pydantic` - Data validation

</details>

<details>
<summary><b>ğŸ¨ Detailed Frontend Setup</b></summary>

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev

# Build for production
npm run build
```

**Built with:**
- `React 18` - UI framework
- `Vite` - Lightning fast bundler
- `Tailwind CSS` - Utility-first styling
- `Lucide React` - Beautiful icons

</details>

---

## âš™ï¸ Configuration

### ğŸ¤ Whisper Models

Edit `backend/core/config.py`:

```python
WHISPER_MODEL: str = "base"  # Options: tiny, base, small, medium, large
```

| Model | RAM | Speed (1hr audio) | Quality |
|:-----:|:---:|:-----------------:|:-------:|
| `tiny` | 1GB | ~5 min | â­â­ |
| `base` | 1.5GB | ~10 min | â­â­â­ |
| `small` | 2.5GB | ~20 min | â­â­â­â­ |
| `medium` | 5GB | ~40 min | â­â­â­â­â­ |

### ğŸ¤– Ollama Models

```python
OLLAMA_MODEL: str = "llama3.1:8b"  # Or any Ollama model
```

---

## ğŸ”Œ API Reference

| Endpoint | Method | Description |
|----------|:------:|-------------|
| `/api/upload` | `POST` | Upload audio file |
| `/api/status/{task_id}` | `GET` | Get transcription progress |
| `/api/result/{task_id}` | `GET` | Get full transcript |
| `/api/summarize` | `POST` | Generate AI summary |
| `/api/export/{format}/{task_id}` | `GET` | Export (txt/srt/vtt/json) |
| `/api/ollama/health` | `GET` | Check Ollama status |

ğŸ“š **Interactive Docs** â†’ [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“ Project Structure

```
Audtext/
â”œâ”€â”€ ğŸ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ api/routes/          # API endpoints
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ whisper_service.py   # Transcription
â”‚   â”‚   â””â”€â”€ ollama_service.py    # Summarization
â”‚   â”œâ”€â”€ core/config.py       # Settings
â”‚   â””â”€â”€ tests/               # Test suite
â”‚
â”œâ”€â”€ âš›ï¸ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx          # Main component
â”‚   â”‚   â”œâ”€â”€ components/      # UI components
â”‚   â”‚   â””â”€â”€ services/api.ts  # API client
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ ğŸ“‚ uploads/              # Temporary storage
```

---

## ğŸ› Troubleshooting

<details>
<summary><b>âŒ "Failed to fetch" on upload</b></summary>

Make sure the backend is running on port 8000:
```bash
uvicorn main:app --reload --port 8000
```

</details>

<details>
<summary><b>âŒ Summary returns 500 error</b></summary>

1. Ensure Ollama is running: `ollama serve`
2. Download the model: `ollama pull llama3.1:8b`
3. Verify: `curl http://localhost:11434/api/tags`

</details>

<details>
<summary><b>âŒ First transcription is slow</b></summary>

The first run downloads the Whisper model (~150MB for base). Subsequent runs are faster.

</details>

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. ğŸ´ **Fork** the repository
2. ğŸŒ¿ **Create** a feature branch (`git checkout -b feature/amazing`)
3. ğŸ’¾ **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. ğŸ“¤ **Push** to the branch (`git push origin feature/amazing`)
5. ğŸ”ƒ **Open** a Pull Request

---

## ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

<div align="center">

| Technology | Purpose |
|:----------:|:--------|
| [ğŸ¤ OpenAI Whisper](https://github.com/openai/whisper) | Speech Recognition |
| [âš¡ faster-whisper](https://github.com/SYSTRAN/faster-whisper) | Optimized Inference |
| [ğŸ¦™ Ollama](https://ollama.ai) | Local LLM Runtime |
| [ğŸš€ FastAPI](https://fastapi.tiangolo.com) | Backend Framework |
| [âš›ï¸ React](https://react.dev) | Frontend Framework |

</div>

---

<div align="center">

### â­ Star this repo if you find it useful!

Made with â¤ï¸ by [Akhil Reddy](https://github.com/DandaAkhilReddy)

<br/>

[![Star History Chart](https://api.star-history.com/svg?repos=DandaAkhilReddy/Audtext&type=Date)](https://star-history.com/#DandaAkhilReddy/Audtext&Date)

</div>
